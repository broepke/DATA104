---
title: "Assignment 13"
author: "Brian Roepkee"
date: "Dec 6, 2020"
output:
  html_document:
    df_print: paged
---
# Sentiment Analysis

1) Read Ch 2 on sentiment analysis as well as sentiment analysis section of Ch 9 to understand how to approach lexicon-based sentiment analysis using tidytext

2) Using the twitter data from your previous assignment with Biden and Trump tweets , perform sentiment analysis using the 'bing' lexicon.  The tweets dataset has been attached.  

3) Compare sentiment between each candidate with full analysis and visualizations.  Show most positive /negative words between each candidate. You can use bar blots and/or comparison.cloud() to group words by positive/negative sentiment.  

## Load Libraries and Data

```{r message=FALSE, warning=FALSE}
# twitter library 
library(rtweet)

# plotting and pipes
library(tidyverse)
library(ggplot2)
library(dplyr)
library(stringr)
library(tidyr)

# text mining library
library(tidytext)
library(wordcloud)
library(reshape2)
library(RColorBrewer)

# date/time library
library(lubridate)
```

```{r}
df <- read.csv("candidates.csv")
```

```{r}
# Convert the date field to a datetime
df$created_at <- as_datetime(df$created_at)

#Changed some fields to factors for easier manipulation later
df$user_id <- as.factor(df$user_id)
df$status_id <- as.factor(df$status_id)
df$screen_name <- as.factor(df$screen_name)

# Fix up the reply count field.  It should be a int and NAs set to 0
df$reply_count[is.na(df$reply_count)] <- 0
df$reply_count <- as.integer(df$reply_count)
```

### Clean Text
Get rid of various useless text like URLS and shorened URLs

```{r}
df$text <- gsub("http\\S+\\s*","", df$text)
df$text <- gsub("t.co","", df$text)
df$text <- gsub("amp","", df$text)
df$text <- gsub("\\n","", df$text)
```


```{r}
head(df)
```
Show the total number of rows in this dataset.

```{r}
nrow(df)
```

#EDA




# Sentiment Analysis

```{r}
df_select <- df %>%
  select(user_id, status_id, screen_name, created_at, text)
```

## Unnest Tokens
Create a new column with each word on it's own row. 

```{r}
tidy_df <- df_select %>%
  unnest_tokens(word, text)
```

### Validate the New number of Rows
This should be dramatically larger now that each word from text is in it's own row.

```{r}
nrow(tidy_df)
```

After unnesting the words, each word of the tweet is on a separate line. The following is an example. 

```{r}
tidy_df %>%
  filter(status_id == "x1319032499456987136") %>%
  head(n=25)
```

### Stop Word Removal
remove stop words and custom stop words from the results.

Note: Removing Trump because it's a proper name but also an verb which was marked as postive and overly  

```{r}
custom_stop_words <- bind_rows(tibble(word = c("trump"), lexicon = c("custom")), stop_words)

tidy_df <-tidy_df %>%
  anti_join(custom_stop_words, by = "word")
```

### Add "Bing" Sentiment

```{r}
tidy_df <- tidy_df %>%
  inner_join(get_sentiments("bing"), by = "word")

head(tidy_df)
```

### Inspect Top Words Per Candidate

```{r message=FALSE, warning=FALSE}
tidy_df %>%
  filter(screen_name == "JoeBiden") %>%
  count(word, sort = TRUE, sentiment)
```


```{r message=FALSE, warning=FALSE}
tidy_df %>%
  filter(screen_name == "realDonaldTrump") %>%
  count(word, sort = TRUE, sentiment)
```

### Top Word Counts

```{r message=FALSE, warning=FALSE}
# Get totals of pos/neg wordcounts
tidy_df %>%
  count(word, sort = TRUE, sentiment) %>%

  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  theme_minimal() +
  labs(x = "Contribution to sentiment",
       y = NULL)
```

### Top Word Count Per Candidate

```{r message=FALSE, warning=FALSE}
# Get totals of pos/neg wordcounts
tidy_df %>%
  count(word, sort = TRUE, screen_name, sentiment) %>%

  group_by(screen_name, sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(vars(screen_name, sentiment), scales = "free_y") +
  theme_minimal() +
  labs(x = "Contribution to sentiment",
       y = NULL)
```

# Sentiment of Tweets over Time

```{r}
plot_df <- tidy_df %>%
  filter(created_at > "2020-08-01") %>%
  mutate(mon = floor_date(created_at, "day")) %>%
  count(screen_name, mon, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)


plot_df$color <- ifelse(plot_df$sentiment < 0, "negative","positive")

ggplot(plot_df, aes(mon, sentiment, fill = color)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~screen_name, ncol = 1, scales = "free_x") +
  theme_minimal()
```



# Word Clouds

## Overall Word Cloud

```{r message=FALSE, warning=FALSE}
tidy_df %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
```

## Word Clouds for Each Candidate

### Biden

```{r message=FALSE, warning=FALSE}
tidy_df %>%
  filter(screen_name == "JoeBiden") %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
```

### Trump

```{r message=FALSE, warning=FALSE}
tidy_df %>%
  filter(screen_name == "realDonaldTrump") %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
```

```{r message=FALSE, warning=FALSE}
tidy_df %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("#F8766D", "#00BFC4"),
                   max.words = 100)
```

```{r}
ggplot(plot_df, aes(x = screen_name, y = sentiment, color = screen_name)) + 
  geom_boxplot() + 
  geom_point() + 
  theme_minimal()
```





