---
title: "Assignment 13"
author: "Brian Roepkee"
date: "Dec 6, 2020"
output:
  html_document:
    df_print: paged
---
# Sentiment Analysis

1) Read Ch 2 on sentiment analysis as well as sentiment analysis section of Ch 9 to understand how to approach lexicon-based sentiment analysis using tidytext

2) Using the twitter data from your previous assignment with Biden and Trump tweets , perform sentiment analysis using the 'bing' lexicon.  The tweets dataset has been attached.  

3) Compare sentiment between each candidate with full analysis and visualizations.  Show most positive /negative words between each candidate. You can use bar blots and/or comparison.cloud() to group words by positive/negative sentiment.  

## Load Libraries and Data

```{r message=FALSE, warning=FALSE}
# twitter library 
library(rtweet)

# plotting and pipes
library(tidyverse)
library(ggplot2)
library(dplyr)
library(stringr)
library(tidyr)

# text mining library
library(tidytext)
library(wordcloud)
library(reshape2)
library(RColorBrewer)

# date/time library
library(lubridate)
```

```{r}
df <- read.csv("candidates.csv")
```

```{r}
# Convert the date field to a datetime
df$created_at <- as_datetime(df$created_at)

#Changed some fields to factors for easier manipulation later
df$user_id <- as.factor(df$user_id)
df$status_id <- as.factor(df$status_id)
df$screen_name <- as.factor(df$screen_name)

# Fix up the reply count field.  It should be a int and NAs set to 0
df$reply_count[is.na(df$reply_count)] <- 0
df$reply_count <- as.integer(df$reply_count)
```


```{r}
head(df)
```
```{r}
tail(df)
```

Show the total number of rows in this dataset.

```{r}
nrow(df)
```

# EDA

Simplify the Dataframe and add a column for text length

```{r}
df$text_len <- str_count(df$text)
```


```{r}
df_select <- df %>%
  select(user_id, status_id, screen_name, created_at, text, text_len)
```

## Tweet Length
Number of tweets by each candidate

```{r}
summary(df_select$text_len)
```

Tweets for the dataset range from `7` characters to `330` with a mean of `172`


```{r}
df_select %>%
  ggplot(aes(x = text_len, fill = screen_name)) +
  geom_histogram(alpha = .5, color = "darkgray", bins = 33) +
  theme_minimal()
```

Plotting a histogram of Tweet lengths It appears that Biden typically has longer tweets than Trump on average

### Tweets Over Time

```{r}
df_select %>%
  dplyr::group_by(screen_name) %>%
  ts_plot("days", trim = 0L) +
  ggplot2::geom_line() +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    legend.title = ggplot2::element_blank(),
    legend.position = "right",
    plot.title = ggplot2::element_text(face = "bold")) +
  ggplot2::labs(
    x = NULL, y = NULL,
    title = "Frequency of Tweets by Candidate by Day"
  )
```

Based on the way this dataset was collected (last 3200 tweets per candidate), the data from Trump is compressed to dates starting around August.  This is due to the fact that he tweets more regularly than Biden, hitting the 3,200 tweet limit sooner.

# Sentiment Analysis

## Clean and Prepare the Text for Analysis

Get rid of various useless text like URLS and shortened URLs.  These appear frequently in the text and skew results.

```{r}
df_select$text <- gsub("http\\S+\\s*","", df_select$text)
df_select$text <- gsub("t.co","", df_select$text)
df_select$text <- gsub("amp","", df_select$text)
df_select$text <- gsub("\\n","", df_select$text)
```

Create a new column with each word on it's own row (Unnesting Tokens)

```{r}
tidy_df <- df_select %>%
  unnest_tokens(word, text)
```

### Validate the New number of Rows
Dramatically larger now that each word from text is in it's own row.

```{r}
nrow(tidy_df)
```

After unnesting the words, each word of the tweet is on a separate line. The following is an example. 

```{r}
tidy_df %>%
  filter(status_id == "x1319032499456987136") %>%
  head(n=25)
```

### Stop Word Removal
remove stop words and custom stop words from the results.

Note: Removing Trump because it's a proper name but also an verb which was marked as postive and appeared in the top results for both candidates. 

```{r}
custom_stop_words <- bind_rows(tibble(word = c("trump"), lexicon = c("custom")), stop_words)

tidy_df <-tidy_df %>%
  anti_join(custom_stop_words, by = "word")
```

### Add "Bing" Sentiment
Using the Bing Lexicon from Bing Liu and collaborators, adds the column "Sentiment" and mark each word as positive or negative. 

https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html

```{r}
tidy_df <- tidy_df %>%
  inner_join(get_sentiments("bing"), by = "word")

head(tidy_df)
```

### Add the AFINN scoring
AFINN from Finn Ã…rup Nielsen, adds the `value` column, with a numeric representation of how postive, or negative the word is.  The AFINN lexicon measures sentiment with a numeric score between -5 and 5

http://www2.imm.dtu.dk/pubdb/pubs/6010-full.html 

```{r}
tidy_df <- tidy_df %>%
  inner_join(get_sentiments("afinn"), by = "word")

tidy_df %>%
  arrange(desc(value)) %>%
  head
```

### Add NRC Sentiment
NRC from Saif Mohammad and Peter Turney. The NRC Emotion Lexicon is a list of English words and their associations with eight basic emotions

```{r}
tidy_df <- tidy_df %>%
  inner_join(get_sentiments("nrc"), by = "word")

head(tidy_df)
```

Fix the column names due to duplicate sentiment names from the various lexicons

```{r}
tidy_df <- rename(tidy_df, "sentiment" = "sentiment.x")
tidy_df <- rename(tidy_df, "emotion" = "sentiment.y")
head(tidy_df)
```


## Inspect Top Words Per Candidate
Using various methods, inspect what words are most frequently used, per candidate, proportions of negative and positive words, and trend over time. 

### Top Word Counts

```{r message=FALSE, warning=FALSE}
# Get totals of pos/neg wordcounts
tidy_df %>%
  count(word, sort = TRUE, sentiment) %>%

  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  theme_minimal() +
  labs(x = "Contribution to sentiment",
       y = NULL)
```

When looking at data as a whole, we can see the top negative word is `crisis` and positive is `win`.  Next, we'll split these out by candidate. 

### Top Word Count Per Candidate

```{r message=FALSE, warning=FALSE}
# Get totals of pos/neg wordcounts
tidy_df %>%
  count(word, sort = TRUE, screen_name, sentiment) %>%

  group_by(screen_name, sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(vars(screen_name, sentiment), scales = "free_y") +
  theme_minimal() +
  labs(x = "Contribution to sentiment",y = NULL)
```

**Negative**: Biden has the top word crisis in his list, where Trump doesn't.  Biden uses threat, hate, worst, fear, in his negative list where Trump has fake, crime, fraud, hoax, crazy, destroy.  Different negative words speaking to different topics. 

**Positive**: Both candidates show win, support, honor, and protect in their top 10. Biden uses promise, safe, fair, grateful.  Trump uses endorsement, peace, strong, congratulations, and wow.  

### Overall Top Words

```{r message=FALSE, warning=FALSE}
# Get totals of pos/neg wordcounts
tidy_df %>%
  count(word, sort = TRUE, sentiment, screen_name) %>%

  group_by(screen_name) %>%
  top_n(30) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = TRUE) +
  facet_wrap(~screen_name, scales = "free_y") +
  theme_minimal() +
  labs(x = "Contribution to sentiment", y = NULL)
```

Looking at the mix of top 30 words and whether they're positive or negative.  Both candidates are about the same. The number one word for each is a negative word.  There is a mix of positive and negative words throughout. 

### Top Words Sorted by AFINN Score

```{r message=FALSE, warning=FALSE}
tidy_df %>%
  count(word, sort = TRUE, sentiment, screen_name, value) %>%

  group_by(screen_name) %>%
  top_n(30) %>%
  ungroup() %>%
  mutate(word = reorder(word, value)) %>%
  ggplot(aes(value, word, fill = sentiment)) +
  geom_col(show.legend = TRUE) +
  facet_wrap(~screen_name, scales = "free_y") +
  theme_minimal() +
  labs(x = "AFINN Sentiment Score", y = NULL)
```
Top 30 words, sorted by their AFINN score, a scale of -5 to 5.  Trump uses slightly more polarizing terms, on the negative side he has 3 that are +4 to Biden's 1, and on the negative side, he has one that is -4 (fraud).  Biden used slightly more postive words in his top 30. 

### Top Emotions Per Candidate
Using the NRC Emotion, we can see how each candidates core emptions stack up.


```{r}
tidy_df %>%
  count(emotion, sort = TRUE, screen_name) %>%

  group_by(screen_name, emotion) %>%
  ungroup() %>%
  mutate(emo = reorder(emotion, n)) %>%
  ggplot(aes(n, emo, fill = emo)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~screen_name, scales = "free_y") +
  theme_minimal() +
  labs(x = "Count",y = "NRC Emotions")
```


### Overall Average Sentiment per Candidate

```{r}
tidy_df %>%
  count(word, sort = TRUE, sentiment, screen_name, value) %>%
  group_by(screen_name) %>%
  summarize(value = sum(value * n), .groups = "keep") %>%
  
  mutate(screen_name = reorder(screen_name, value)) %>%
  ggplot(aes(value, screen_name, fill = value > 0)) +
  geom_col(show.legend = FALSE) +
  labs(x = "Average sentiment value", y = NULL) +
  theme_minimal() +
  geom_text(aes(label = value), position = position_stack(vjust = 0.5))
```

Computing the average total sentiment, both candidates are in the negative range.  Trump's overall score is greater than Biden's.

### Sentiment of Tweets over Time

```{r}
plot_df <- tidy_df %>%
  filter(created_at > "2020-08-01") %>%
  mutate(mon = floor_date(created_at, "day")) %>%
  count(screen_name, mon, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)


plot_df$color <- ifelse(plot_df$sentiment < 0, "negative","positive")

ggplot(plot_df, aes(mon, sentiment, fill = color)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~screen_name, ncol = 1, scales = "free_x") +
  labs(x = NULL, y = "Frequency of Sentiment") +
  theme_minimal()
```

Since August, showing the frequency of sentiment for each candidate.  Trump tweets more than Biden on average, therefore the peaks are larger. Trump appears to tweet negative tweets more frequently than Trump.

# Word Clouds

## Overall Word Cloud

```{r message=FALSE, warning=FALSE}
tidy_df %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 200))
```

## Word Clouds for Each Candidate

### Biden

```{r message=FALSE, warning=FALSE}
tidy_df %>%
  filter(screen_name == "JoeBiden") %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 200))
```

### Trump

```{r message=FALSE, warning=FALSE}
tidy_df %>%
  filter(screen_name == "realDonaldTrump") %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 200))
```

```{r message=FALSE, warning=FALSE}
tidy_df %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("#F8766D", "#00BFC4"), max.words = 200)
```







